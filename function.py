import prompts
import logging
import time as time_module
import pandas as pd 
import os
import psycopg2
from datetime import datetime, timedelta, date,time
from decimal import Decimal
import json
import sqlite3
import re
from flask import Response, redirect



def generate_openai_reply(prompt,client):
    try:
        response = client.chat.completions.create(
            model="gpt-4",  # or your preferred model
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are Leajlak's customer service assistant (Leajlak's Order Management System connects merchants "
                        "and third-party logistics companies for on-demand express and scheduled deliveries, leveraging AI, IoT, "
                        "and Big Data to boost efficiency, cut costs, and improve customer satisfaction). "
                        "Check the user's message and send appropriate replies that are always inside the above context."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=150,
            temperature=0.7,
        )
        reply = response.choices[0].message.content.strip()
        return (str(reply))
    except Exception as e:
        logging.error(f"OpenAI API error: {e}")
        return "Sorry, something went wrong while generating the reply."
    


def generate_sql_with_openai(prompt,client,system):
    try:
        sql_prompt=system
        logging.info('started sql generation')
        response = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[
                {
                    "role":"system",
                    "content":sql_prompt
                },
                {
                "role":"user",
                "content":prompt
                }
            ]
        )
        sql_query = response.choices[0].message.content
        logging.info(f"Generated SQL query: {sql_query}")
        return sql_query
        
    except Exception as e:
        logging.info(f"OpenAI API error: {str(e)}")
        raise

def generate_sql_with_openrouter(prompt, client, system):
    try:
        sql_prompt = system
        logging.info('Started SQL generation')

        response = client.chat.completions.create(
            model="anthropic/claude-3-haiku",
            messages=[
                {
                    "role": "system",
                    "content": sql_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )

        # Access response correctly
        sql_query = response.choices[0].message.content

        logging.info(f"Generated SQL query: {sql_query}")
        return sql_query

    except Exception as e:
        logging.error(f"OpenRouter API error: {str(e)}")
        raise



def generate_streaming_response(context,prompt_analysis, client2,system, wpm=350):
   
    """
    Generate streaming response for analysis
    """
    try:
        summary_prompt = system
        logging.info('Started summary generation')
        
        response = client2.chat.completions.create(
            model="deepseek/deepseek-chat-v3-0324",
            stream=True,
            messages=[
                {
                    "role": "system",
                    "content": summary_prompt
                },
                {
                    "role": "user",
                    "content": prompt_analysis
                },
                {
                    "role": "user",
                    "content": context      
                }
            ]
        ) 
        
        for chunk in response:
            
            delta = chunk.choices[0].delta  
            #logging.info(f'delta: {len(delta.__dict__)}')
            
            if hasattr(delta, 'content') and delta.content:
                try:
                    yield delta.content.encode('utf-8')
                    char_count = len(delta.content)
                    delay = (char_count * 30.0) / (wpm * 5)
                    time_module.sleep(delay)
                except Exception as e:
                    logging.error(f'Streaming error: {str(e)}')
                    
    except Exception as e:
        logging.error(f'Response creation failed: {str(e)}')
        yield f"Error: {str(e)}".encode('utf-8')


#saving user message to file

def append_messages_to_excel(messages, filename='data/user_messages.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'message': messages})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'message': messages})
    combined_df.to_excel(filename, index=False)

#saving summary generated by llm to file

def append_summaries_to_excel(summary, filename='data/summary.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'summary': summary})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'summary': summary})
    combined_df.to_excel(filename, index=False)

#saving the sql generated

def append_sql_to_excel(sql, filename='data/sql.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'sql': sql})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'sql': sql})
    combined_df.to_excel(filename, index=False)




class SafeJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder for PostgreSQL data types"""
    def default(self, obj):
        if isinstance(obj, (datetime, date, time)):
            return obj.isoformat()
        elif isinstance(obj, timedelta):
            return str(obj.total_seconds())  # Convert to seconds
        elif isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)


def execute_query_and_get_json(db_url, sql_query):

    try:
        with psycopg2.connect(db_url) as conn:
            with conn.cursor() as cur:
                cur.execute(sql_query)
                rows = cur.fetchall()
                colnames = [desc[0] for desc in cur.description]
                
                # Convert rows to serializable format
                list_of_dicts = []
                for row in rows:
                    row_dict = {}
                    for col, val in zip(colnames, row):
                        if isinstance(val, (datetime, date)):
                            row_dict[col] = val.isoformat()
                        elif isinstance(val, timedelta):
                            row_dict[col] = val.total_seconds()
                        elif isinstance(val, Decimal):
                            row_dict[col] = float(val)
                        else:
                            row_dict[col] = val
                    list_of_dicts.append(row_dict)
                
                try:
                    db_data_json = json.dumps(list_of_dicts, indent=2, cls=SafeJSONEncoder)
                    logging.info(f'Database fetching successful: {len(str(db_data_json))}')
                    return db_data_json, True
                except Exception as json_error:
                    logging.error(f'JSON serialization error: {str(json_error)}')
                    return None, False
                    
    except psycopg2.Error as db_error:
        logging.error(f'Database error: {str(db_error)}')
        return None, False
    except Exception as general_error:
        logging.error(f'General error in query execution: {str(general_error)}')
        return None, False
    

## storing the user context

def init_db():
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_context (
            session_id TEXT,
            message_id INTEGER PRIMARY KEY AUTOINCREMENT,
            message_role TEXT NOT NULL,
            message_text TEXT NOT NULL,
            response TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS data_context (
            session_id TEXT,
            data_id INTEGER PRIMARY KEY AUTOINCREMENT,
            data TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()

init_db()


def store_message(session_id, message_text, message_role,response):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO user_context (session_id, message_text, message_role,response)
            VALUES (?, ?, ?,?)
        """, (session_id, message_text, message_role,response))
        logging.info('context stored successfully')
    except Exception as e:
        logging.error(f'error storing info: {str(e)}')
    try:
        cursor.execute("""
            DELETE FROM user_context
            WHERE session_id = ?
            AND message_id NOT IN (
                SELECT message_id
                FROM user_context
                WHERE session_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            )
        """, (session_id, session_id, 5))
    except Exception as e:
        logging.error(f'error deleting old context:{str(e)}')

    conn.commit()
    conn.close()

def store_data(session_id,data):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO data_context (session_id, data)
            VALUES (?, ?)
        """, (session_id, data))
        logging.info('data from database stored successfully')
    except Exception as e:
        logging.error(f'error storing info: {str(e)}')

    cursor.execute("""
        DELETE FROM data_context
        WHERE session_id = ?
        AND data_id NOT IN (
            SELECT data_id
            FROM data_context
            WHERE session_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        )
    """, (session_id, session_id, 5))

    conn.commit()
    conn.close()

def get_context_messages(session_id):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT message_role, message_text, response FROM user_context
            WHERE session_id = ?
            ORDER BY timestamp ASC
        """, (session_id,))
        logging.info('context fetched succcessfully')
    except Exception as e :
        logging.error(f'error getting context:{str(e)}')
        return[]    
    
    messages = cursor.fetchall()
    conn.close()

    return [
        {"role": role, "content": f"user message :{text}, model response : {str(response)}".strip()}
        for role, text, response in messages
    ]

def get_db_data(session_id):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT data FROM data_context
            WHERE session_id = ?
            ORDER BY timestamp DESC
        """,(session_id,))
        result =cursor.fetchone()
        if result:
            logging.info('db_data fetched for followup')
            return result[0]
        else:
            return None
    except Exception as e:
        logging.error(f'(db_get_data)errorr getting db data for followup {str(e)}')
    finally :
        conn.close()



def store_and_stream(original_generator, session_id, user_message):
    collected_chunks = []
    try:
        for chunk in original_generator:
            collected_chunks.append(chunk)  # Collect for storage
            yield chunk  # Stream to client
    finally:
        full_message = b''.join(collected_chunks).decode('utf-8')
        try:
            store_message(session_id, user_message, 'user', full_message)
        except Exception as e:
            logging.error(f'Failed to store message context={e}')





def classify_followup(user_message, context, db_data_json, client):
    try:
        classification_prompt = f"""
        This is the current user question: "{user_message}"
        Previous chat context: "{context}"
        Data fetched from the database for the previous question: "{db_data_json}"

        If the user message relates to the previous context and database data (i.e., it's a follow-up question), return exactly 'followup'.
        Otherwise, return exactly 'new_question'."""
        
        response = client.chat.completions.create(
            model="anthropic/claude-3-haiku",
            messages=[
                {
                    "role": "system",
                    "content": "you are a classifier who only returns 'followup' or 'new_question'"
                },
                {
                    "role": "user",
                    "content": classification_prompt
                }
            ]
        )
        reply = response.choices[0].message.content

        logging.info(f"Generated SQL query: {reply}")
        return reply
    except Exception as e:
        logging.error(f"OpenRouter API error: {str(e)}")
    