import prompts
import logging
import time as time_module
import pandas as pd 
import os
import psycopg2
from datetime import datetime, timedelta, date,time
from decimal import Decimal
import json
import sqlite3
from flask import jsonify

from datetime import datetime

    


    
def generate_openrouter_reply(prompt, client):
    try:
        response = client.chat.completions.create(
            model="openai/gpt-4.1-mini",  # pick model via OpenRouter
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are Leajlak's customer service assistant (Leajlak's Order Management System connects merchants "
                        "and third-party logistics companies for on-demand express and scheduled deliveries, leveraging AI, IoT, "
                        "and Big Data to boost efficiency, cut costs, and improve customer satisfaction). "
                        "Check the user's message and send appropriate replies that are always inside the above context."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=150,
            temperature=0.7,
        )
        reply = response.choices[0].message.content.strip()
        return reply
    except Exception as e:
        logging.error(f"OpenRouter API error: {e}")
        return "Sorry, something went wrong while generating the reply."




def generate_sql_with_openrouter(prompt, client, system):
    try:
        sql_prompt = system
        logging.info('Started SQL generation')

        response = client.chat.completions.create(
            model="anthropic/claude-3.5-sonnet",
            messages=[
                {
                    "role": "system",
                    "content": sql_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )

        # Access response correctly
        sql_query = response.choices[0].message.content

        logging.info(f"Generated SQL query: {sql_query}")
        return sql_query

    except Exception as e:
        logging.error(f"OpenRouter API error: {str(e)}")
        raise



def generate_streaming_response(context,prompt_analysis, client2,system, wpm=350):
    try:
        summary_prompt = system
        logging.info('Started summary generation')
        
        response = client2.chat.completions.create(
            model="mistralai/mistral-7b-instruct",
            stream=True,
            messages=[
                {
                    "role": "system",
                    "content": summary_prompt
                },
                {
                    "role": "user",
                    "content": prompt_analysis
                },
                {
                    "role": "user",
                    "content": context      
                }
            ],
            max_tokens=50
        ) 
        
        for chunk in response:
            
            delta = chunk.choices[0].delta  
            #logging.info(f'delta: {len(delta.__dict__)}')
            
            if hasattr(delta, 'content') and delta.content:
                try:
                    yield delta.content.encode('utf-8')
                    char_count = len(delta.content)
                    delay = (char_count * 30.0) / (wpm * 5)
                    time_module.sleep(delay)
                except Exception as e:
                    logging.error(f'Streaming error: {str(e)}')
                    
    except Exception as e:
        logging.error(f'Response creation failed: {str(e)}')
        yield f"Error: {str(e)}".encode('utf-8')


#saving user message to file

def append_messages_to_excel(messages, filename='data/user_messages.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'message': messages})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'message': messages})
    combined_df.to_excel(filename, index=False)

#saving summary generated by llm to file

def append_summaries_to_excel(summary, filename='data/summary.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'summary': summary})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'summary': summary})
    combined_df.to_excel(filename, index=False)

#saving the sql generated

def append_sql_to_excel(sql, filename='data/sql.xlsx'):
    if os.path.exists(filename):
        existing_df = pd.read_excel(filename)
        new_df = pd.DataFrame({'sql': sql})
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        combined_df = pd.DataFrame({'sql': sql})
    combined_df.to_excel(filename, index=False)




class SafeJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder for PostgreSQL data types"""
    def default(self, obj):
        if isinstance(obj, (datetime, date, time)):
            return obj.isoformat()
        elif isinstance(obj, timedelta):
            return str(obj.total_seconds())  # Convert to seconds
        elif isinstance(obj, Decimal):
            return float(obj)
        return super().default(obj)


def execute_query_and_get_json(db_url, sql_query):

    try:
        with psycopg2.connect(db_url) as conn:
            with conn.cursor() as cur:
                cur.execute(sql_query)
                rows = cur.fetchall()
                colnames = [desc[0] for desc in cur.description]
                
                # Convert rows to serializable format
                list_of_dicts = []
                for row in rows:
                    row_dict = {}
                    for col, val in zip(colnames, row):
                        if isinstance(val, (datetime, date)):
                            row_dict[col] = val.isoformat()
                        elif isinstance(val, timedelta):
                            row_dict[col] = val.total_seconds()
                        elif isinstance(val, Decimal):
                            row_dict[col] = float(val)
                        else:
                            row_dict[col] = val
                    list_of_dicts.append(row_dict)
                
                try:
                    db_data_json = json.dumps(list_of_dicts, indent=2, cls=SafeJSONEncoder)
                    logging.info(f'Database fetching successful: {str(db_data_json)}')
                    return db_data_json, True
                except Exception as json_error:
                    logging.error(f'JSON serialization error: {str(json_error)}')
                    return None, False
                    
    except psycopg2.Error as db_error:
        logging.error(f'Database error: {str(db_error)}')
        return None, False
    except Exception as general_error:
        logging.error(f'General error in query execution: {str(general_error)}')
        return None, False
    

## storing the user context

def init_db():
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_context (
            session_id TEXT,
            message_id INTEGER PRIMARY KEY AUTOINCREMENT,
            message_role TEXT NOT NULL,
            message_text TEXT NOT NULL,
            response TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS data_context (
            session_id TEXT,
            data_id INTEGER PRIMARY KEY AUTOINCREMENT,
            data TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()

init_db()


def store_message(session_id, message_text, message_role):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO user_context (session_id, message_text, message_role)
            VALUES (?, ?, ?)
        """, (session_id, message_text, message_role))
        logging.info('context stored successfully')
    except Exception as e:
        logging.error(f'error storing info: {str(e)}')
    try:
        cursor.execute("""
            DELETE FROM user_context
            WHERE session_id = ?
            AND message_id NOT IN (
                SELECT message_id
                FROM user_context
                WHERE session_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            )
        """, (session_id, session_id, 5))
    except Exception as e:
        logging.error(f'error deleting old context:{str(e)}')

    conn.commit()
    conn.close()

def store_data(session_id,data):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO data_context (session_id, data)
            VALUES (?, ?)
        """, (session_id, data))
        logging.info('data from database stored successfully')
    except Exception as e:
        logging.error(f'error storing info: {str(e)}')

    cursor.execute("""
        DELETE FROM data_context
        WHERE session_id = ?
        AND data_id NOT IN (
            SELECT data_id
            FROM data_context
            WHERE session_id = ?
            ORDER BY timestamp DESC
            LIMIT ?
        )
    """, (session_id, session_id, 5))

    conn.commit()
    conn.close()

def get_context_messages(session_id):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT message_role, message_text FROM user_context
            WHERE session_id = ?
            ORDER BY timestamp ASC
        """, (session_id,))
        logging.info('context fetched successfully')
    except Exception as e:
        logging.error(f'error getting context:{str(e)}')
        return []
    
    messages = cursor.fetchall()
    conn.close()

    return [
        {"role": role, "content": text}
        for role, text in messages
    ]

def get_db_data(session_id):
    conn = sqlite3.connect('instance/chat_context.db')
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT data FROM data_context
            WHERE session_id = ?
            ORDER BY timestamp DESC
        """,(session_id,))
        result =cursor.fetchone()
        if result:
            logging.info('db_data fetched for followup')
            return result[0]
        else:
            return None
    except Exception as e:
        logging.error(f'(db_get_data)errorr getting db data for followup {str(e)}')
    finally :
        conn.close()



def store_and_stream(original_generator, session_id, user_message):
    collected_chunks = []
    try:
        for chunk in original_generator:
            collected_chunks.append(chunk)  # Collect for storage
            yield chunk  # Stream to client
    finally:
        full_message = b''.join(collected_chunks).decode('utf-8')
        logging.info(f'{full_message}')
        try:
            store_message(session_id, user_message, 'user', full_message)
        except Exception as e:
            logging.error(f'Failed to store message context={e}')





def classify_followup(user_message, context, db_data_json, client):
    try:
        system_prompt = (
            "You are a strict binary classifier for a chatbot. "
            "You must return only one word: 'followup' or 'new_question'. "
            "Definitions:"
            "- 'followup' → if the user's latest message depends on or refers to previous context or database results. "
            "Examples: vague pronouns ('it', 'that order'), short interrogatives ('who', 'when', 'where', 'status?'), "
            "or mentions of IDs/tracking numbers seen earlier."
            "- 'new_question' → if the message is independent, general, or about Leajlak services in a new context, "
            "not tied to prior conversation or DB data."
            "Always decide strictly and output only 'followup' or 'new_question'. No punctuation, no explanation."
        )

        classification_prompt = f"""
        Current user question: "{user_message}"
        Previous chat context: "{context}"
        Database results: "{db_data_json}"
        """

        response = client.chat.completions.create(
            model="openai/gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": classification_prompt}
            ],
            max_tokens=16,
            temperature=0.0,
        )
        reply = response.choices[0].message.content.strip().lower()

        # Safety check
        if reply not in ["followup", "new_question"]:
            logging.warning(f"Unexpected classifier output: {reply}")
            return "new_question"  # fallback safe default

        logging.info(f"Follow-up classification: {reply}")
        return reply

    except Exception as e:
        logging.error(f"Follow-up classifier error: {str(e)}", exc_info=True)
        return "new_question"  # safe fallback

def followup_response(user_message, context, db_data, client,session_id):
    """
    Generate response for followup questions using previous context and data.
    
    Args:
        user_message: Current user question
        context: Previous conversation history
        db_data: Data from previous database query
        client: OpenAI/OpenRouter client
        
    Returns:
        tuple: (response_dict, status_code) for Flask jsonify
    """
    try:
        # Format context for prompt
        context_str = ""
        if context:
            if isinstance(context, list):
                context_str = "\n".join([
                    f"{msg.get('role', 'user')}: {msg.get('content', '')}" 
                    for msg in context[-5:]  # Last 5 messages for relevance
                ])
            else:
                context_str = str(context)
        
        # Format database data
        db_data_str = ""
        if db_data:
            if isinstance(db_data, list):
                db_data_str = "\n".join([str(item) for item in db_data])
            else:
                db_data_str = str(db_data)
        
        # Create prompt for followup question
        system_prompt = """You are a helpful assistant for Leajlak logistics. 
        Answer the user's followup question based on the previous conversation and data provided.
        Be concise and directly answer what they're asking about.
        If the answer isn't in the provided data, politely say so."""
        
        user_prompt = f"""
        User's current question: {user_message}
        Previous conversation:
        {context_str}
        Relevant data from previous query:
        {db_data_str}
        Please answer the user's question based on the above context and data."""

        # Generate response
        response = client.chat.completions.create(
            model="qwen/qwen3-next-80b-a3b-instruct",  # Use your preferred model
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=500,
            timeout=30
        )
        
        assistant_response = response.choices[0].message.content.strip()
        logging.info(f'Followup response generated: {assistant_response[:100]}...')
        
        # Store conversation context
        try:
            store_message(session_id, user_message, 'user')
            store_message(session_id, assistant_response, 'assistant')
            logging.info(f'Followup context stored for session {session_id}')
        except Exception as e:
            logging.error(f'Failed to store followup context: {e}')
        
        return assistant_response, 200, {'Content-Type': 'text/plain'}
        
    except Exception as e:
        logging.error(f'Error generating followup response: {str(e)}')
        return jsonify({"error": "Failed to generate followup response"}), 500
    
def generate_response(context, prompt_analysis, client, system_prompt):
    """Generate complete response without streaming."""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt_analysis}
    ]
    
    response = client.chat.completions.create(
        model="deepseek/deepseek-chat",
        messages=messages,
        stream=False  # No streaming
    )
    
    return response.choices[0].message.content



def append_conversation_to_excel(user_message, bot_response,session_id, excel_file='data/conversations.xlsx'):
    """
    Append user message and bot response to Excel file.
    
    Args:
        user_message: User's message
        bot_response: Bot's response
        excel_file: Path to Excel file
    """

    # Prepare data
    data = {
        'Timestamp': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
        'User Message': [user_message],
        'Bot Response': [bot_response],
        'Session ID': [session_id]
    }
    
    df_new = pd.DataFrame(data)
    
    try:
        # Check if file exists
        if os.path.exists(excel_file):
            # Read existing data
            df_existing = pd.read_excel(excel_file)
            # Append new data
            df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        else:
            df_combined = df_new
        
        # Save to Excel
        df_combined.to_excel(excel_file, index=False)
        logging.info(f'Conversation appended to {excel_file}')
        
    except Exception as e:
        logging.error(f'Error appending to Excel: {e}')
        raise